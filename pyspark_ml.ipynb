{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, LogisticRegression, GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StringIndexer, Tokenizer, VectorAssembler\n",
    "from pyspark.ml.feature import HashingTF, IDF, StopWordsRemover\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import regexp_replace, round\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "                    .master('local[*]') \\\n",
    "                    .appName('ML_apache_spark') \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flight data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275000\n",
      "root\n",
      " |-- mon: integer (nullable = true)\n",
      " |-- dom: integer (nullable = true)\n",
      " |-- dow: integer (nullable = true)\n",
      " |-- carrier: string (nullable = true)\n",
      " |-- flight: integer (nullable = true)\n",
      " |-- org: string (nullable = true)\n",
      " |-- mile: integer (nullable = true)\n",
      " |-- depart: double (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- delay: integer (nullable = true)\n",
      "\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "| 10| 10|  1|     OO|  5836|ORD| 157|  8.18|      51|   27|\n",
      "|  1|  4|  1|     OO|  5866|ORD| 466|  15.5|     102| null|\n",
      "| 11| 22|  1|     OO|  6016|ORD| 738|  7.17|     127|  -19|\n",
      "|  2| 14|  5|     B6|   199|JFK|2248| 21.17|     365|   60|\n",
      "|  5| 25|  3|     WN|  1675|SJC| 386| 12.92|      85|   22|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = r\"C:\\Users\\se.vi.dmitriev\\Downloads\\DS Materials\\scripts\\flights-larger.csv\"\n",
    "df = spark.read.csv(path, header=True, inferSchema=True, nullValue='NA')\n",
    "print(df.count())\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+----+------+--------+-----+\n",
      "|mon|dom|dow|carrier|org|mile|depart|duration|delay|\n",
      "+---+---+---+-------+---+----+------+--------+-----+\n",
      "| 10| 10|  1|     OO|ORD| 157|  8.18|      51|   27|\n",
      "|  1|  4|  1|     OO|ORD| 466|  15.5|     102| null|\n",
      "| 11| 22|  1|     OO|ORD| 738|  7.17|     127|  -19|\n",
      "|  2| 14|  5|     B6|JFK|2248| 21.17|     365|   60|\n",
      "|  5| 25|  3|     WN|SJC| 386| 12.92|      85|   22|\n",
      "+---+---+---+-------+---+----+------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.drop('flight')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+----+------+--------+-----+\n",
      "|mon|dom|dow|carrier|org|mile|depart|duration|delay|\n",
      "+---+---+---+-------+---+----+------+--------+-----+\n",
      "| 10| 10|  1|     OO|ORD| 157|  8.18|      51|   27|\n",
      "| 11| 22|  1|     OO|ORD| 738|  7.17|     127|  -19|\n",
      "|  2| 14|  5|     B6|JFK|2248| 21.17|     365|   60|\n",
      "|  5| 25|  3|     WN|SJC| 386| 12.92|      85|   22|\n",
      "|  3| 28|  1|     B6|LGA|1076| 13.33|     182|   70|\n",
      "+---+---+---+-------+---+----+------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.filter(df['delay'].isNotNull())\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|\n",
      "+---+---+---+-------+---+------+--------+-----+------+\n",
      "| 10| 10|  1|     OO|ORD|  8.18|      51|   27| 253.0|\n",
      "| 11| 22|  1|     OO|ORD|  7.17|     127|  -19|1188.0|\n",
      "|  2| 14|  5|     B6|JFK| 21.17|     365|   60|3618.0|\n",
      "|  5| 25|  3|     WN|SJC| 12.92|      85|   22| 621.0|\n",
      "|  3| 28|  1|     B6|LGA| 13.33|     182|   70|1732.0|\n",
      "+---+---+---+-------+---+------+--------+-----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_km = df.withColumn('km', round(df['mile'] * 1.60934, 0)).drop('mile')\n",
    "df_km.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
      "| 10| 10|  1|     OO|ORD|  8.18|      51|   27| 253.0|    1|\n",
      "| 11| 22|  1|     OO|ORD|  7.17|     127|  -19|1188.0|    0|\n",
      "|  2| 14|  5|     B6|JFK| 21.17|     365|   60|3618.0|    1|\n",
      "|  5| 25|  3|     WN|SJC| 12.92|      85|   22| 621.0|    1|\n",
      "|  3| 28|  1|     B6|LGA| 13.33|     182|   70|1732.0|    1|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_km = df_km.withColumn('label', F.when(df_km['delay'] >= 15, 1).otherwise(0))\n",
    "df_km.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+-----+-------+-------------+-------------+--------------------+--------------------+--------------------+----------+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|org_idx|    org_dummy|    dow_dummy|            features|       rawPrediction|         probability|prediction|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-------+-------------+-------------+--------------------+--------------------+--------------------+----------+\n",
      "|  0|  1|  2|     AA|JFK| 14.92|     245|    6|2239.0|    0|    2.0|(7,[2],[1.0])|(6,[2],[1.0])|(14,[0,3,10],[223...|[-0.0917681676909...|[0.45424428643828...|       1.0|\n",
      "|  0|  1|  2|     AA|LGA|   6.0|     240|   45|2235.0|    1|    3.0|(7,[3],[1.0])|(6,[2],[1.0])|(14,[0,4,10],[223...|[-0.1114909574302...|[0.44448435503825...|       1.0|\n",
      "|  0|  1|  2|     AA|LGA| 15.33|     190|    4|1765.0|    0|    3.0|(7,[3],[1.0])|(6,[2],[1.0])|(14,[0,4,10],[176...|[-0.1527358629289...|[0.42422042228276...|       1.0|\n",
      "|  0|  1|  2|     AA|LGA| 15.58|     160|   20|1180.0|    1|    3.0|(7,[3],[1.0])|(6,[2],[1.0])|(14,[0,4,10],[118...|[-0.1448208210752...|[0.42809160126597...|       1.0|\n",
      "|  0|  1|  2|     AA|LGA| 19.75|     170|   -1|1427.0|    0|    3.0|(7,[3],[1.0])|(6,[2],[1.0])|(14,[0,4,10],[142...|[-0.0976391279254...|[0.45133498551028...|       1.0|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-------+-------------+-------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_km_train, df_km_test = df_km.randomSplit([0.8, 0.2], seed=123)\n",
    "\n",
    "org_indexer = StringIndexer(inputCol='org', outputCol='org_idx')\n",
    "one_hot = OneHotEncoder(inputCols=['org_idx', 'dow'], outputCols=['org_dummy', 'dow_dummy'])\n",
    "assembler = VectorAssembler(inputCols=['km', 'org_dummy', 'dow_dummy'], outputCol='features')\n",
    "grad_boost = GBTClassifier(featuresCol='features', labelCol='label')\n",
    "\n",
    "pipeline = Pipeline(stages=[org_indexer, one_hot, assembler, grad_boost])\n",
    "\n",
    "grid = ParamGridBuilder().build()\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='accuracy')\n",
    "\n",
    "cv = CrossValidator(estimator=pipeline,\n",
    "                    estimatorParamMaps=grid,\n",
    "                    evaluator=evaluator,\n",
    "                    numFolds=3,\n",
    "                    seed=123)\n",
    "\n",
    "cv_model = cv.fit(df_km_train)\n",
    "predictions = cv_model.transform(df_km_test)\n",
    "predictions.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5837219243024792"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(14, {0: 0.3028, 1: 0.0739, 2: 0.0749, 3: 0.1016, 4: 0.1177, 5: 0.0859, 6: 0.026, 7: 0.0127, 8: 0.0429, 9: 0.038, 10: 0.0131, 11: 0.0107, 12: 0.0273, 13: 0.0725})"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model.bestModel.stages[3].featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_km_train, df_km_test = df_km.randomSplit([0.8, 0.2], seed=123)\n",
    "\n",
    "# Create Pipeline\n",
    "org_indexer = StringIndexer(inputCol='org', outputCol='org_idx')\n",
    "one_hot = OneHotEncoder(inputCols=['org_idx', 'dow'], outputCols=['org_dummy', 'dow_dummy'])\n",
    "assembler = VectorAssembler(inputCols=['km', 'org_dummy', 'dow_dummy'], outputCol='features')\n",
    "regression = LinearRegression(featuresCol='features', labelCol='duration')\n",
    "\n",
    "pipeline = Pipeline(stages=[org_indexer, one_hot, assembler, regression])\n",
    "\n",
    "grid = ParamGridBuilder() \\\n",
    "            .addGrid(regression.regParam, [0.01, 0.1, 1.0, 10.0]) \\\n",
    "            .addGrid(regression.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "            .build()\n",
    "\n",
    "evaluator = RegressionEvaluator(predictionCol='prediction', labelCol='duration', metricName='rmse')\n",
    "\n",
    "cv = CrossValidator(estimator=pipeline,\n",
    "                    estimatorParamMaps=grid,\n",
    "                    evaluator=evaluator,\n",
    "                    numFolds=3,\n",
    "                    seed=123)\n",
    "\n",
    "cv_model = cv.fit(df_km_train)\n",
    "predictions = cv_model.transform(df_km_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'regParam: regularization parameter (>= 0). (default: 0.0, current: 0.01)'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model.bestModel.stages[3].explainParam('regParam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0742, 28.2962, 20.24, 52.4901, 46.7533, 15.6219, 17.9826, 17.965, 0.0813, -0.1033, -0.0583, -0.0383, -0.0641, -0.1285])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model.bestModel.stages[3].coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11.052413498108365,\n",
       " 11.052659240793442,\n",
       " 11.053492405495746,\n",
       " 11.054343422161995,\n",
       " 11.085017269097982,\n",
       " 11.159554307857988,\n",
       " 11.175207198941633,\n",
       " 11.508601873691342,\n",
       " 11.68709254875606,\n",
       " 14.533931464708136,\n",
       " 17.010321330716437,\n",
       " 19.196764340956136]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+-----+-------+-------------+-------------+--------------------+------------------+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|org_idx|    org_dummy|    dow_dummy|            features|        prediction|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-------+-------------+-------------+--------------------+------------------+\n",
      "|  0|  1|  2|     AA|JFK| 14.92|     245|    6|2239.0|    0|    2.0|(7,[2],[1.0])|(6,[2],[1.0])|(14,[0,3,10],[223...|234.73261405569363|\n",
      "|  0|  1|  2|     AA|LGA|   6.0|     240|   45|2235.0|    1|    3.0|(7,[3],[1.0])|(6,[2],[1.0])|(14,[0,4,10],[223...|228.69894491497925|\n",
      "|  0|  1|  2|     AA|LGA| 15.33|     190|    4|1765.0|    0|    3.0|(7,[3],[1.0])|(6,[2],[1.0])|(14,[0,4,10],[176...|193.81736450835942|\n",
      "|  0|  1|  2|     AA|LGA| 15.58|     160|   20|1180.0|    1|    3.0|(7,[3],[1.0])|(6,[2],[1.0])|(14,[0,4,10],[118...| 150.4009293213965|\n",
      "|  0|  1|  2|     AA|LGA| 19.75|     170|   -1|1427.0|    0|    3.0|(7,[3],[1.0])|(6,[2],[1.0])|(14,[0,4,10],[142...|168.73231306700308|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-------+-------------+-------------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.988867765829333\n"
     ]
    }
   ],
   "source": [
    "rmse = evaluator.evaluate(predictions)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.986938664677428\n"
     ]
    }
   ],
   "source": [
    "print(model.stages[3].intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
      "| 10| 10|  1|     OO|ORD|  8.18|      51|   27| 253.0|    1|\n",
      "| 11| 22|  1|     OO|ORD|  7.17|     127|  -19|1188.0|    0|\n",
      "|  2| 14|  5|     B6|JFK| 21.17|     365|   60|3618.0|    1|\n",
      "|  5| 25|  3|     WN|SJC| 12.92|      85|   22| 621.0|    1|\n",
      "|  3| 28|  1|     B6|LGA| 13.33|     182|   70|1732.0|    1|\n",
      "|  5| 28|  6|     B6|ORD|  9.58|     130|   47|1191.0|    1|\n",
      "|  1| 19|  2|     UA|SFO| 12.75|     123|  135|1093.0|    1|\n",
      "|  8|  5|  5|     US|LGA|  13.0|      71|  -10| 344.0|    0|\n",
      "|  5| 27|  5|     AA|ORD| 14.42|     195|  -11|1926.0|    0|\n",
      "|  8| 20|  6|     B6|JFK| 14.67|     198|   20|1902.0|    1|\n",
      "|  2|  3|  1|     AA|JFK| 15.92|     200|   -9|1754.0|    0|\n",
      "|  8| 26|  5|     B6|JFK| 20.58|     193|  102|1654.0|    1|\n",
      "|  4|  9|  5|     AA|ORD|  20.5|     125|   32|1180.0|    1|\n",
      "|  3|  8|  2|     UA|ORD| 10.95|     129|   55|1180.0|    1|\n",
      "|  8| 10|  3|     OH|LGA| 11.75|     102|    8| 470.0|    0|\n",
      "|  8| 14|  0|     UA|ORD| 17.92|     109|   57| 985.0|    1|\n",
      "|  4|  8|  4|     OH|JFK| 13.25|      88|   23| 484.0|    1|\n",
      "|  1| 14|  4|     UA|SFO| 14.87|      91|   27| 666.0|    1|\n",
      "|  1|  2|  6|     AA|ORD|   7.5|     275|   26|2971.0|    1|\n",
      "|  6| 13|  0|     WN|SFO|  6.92|      80|  -10| 542.0|    0|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_km.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|carrier_idx|org_idx|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+\n",
      "| 10| 10|  1|     OO|ORD|  8.18|      51|   27| 253.0|    1|        2.0|    0.0|\n",
      "| 11| 22|  1|     OO|ORD|  7.17|     127|  -19|1188.0|    0|        2.0|    0.0|\n",
      "|  2| 14|  5|     B6|JFK| 21.17|     365|   60|3618.0|    1|        4.0|    2.0|\n",
      "|  5| 25|  3|     WN|SJC| 12.92|      85|   22| 621.0|    1|        3.0|    5.0|\n",
      "|  3| 28|  1|     B6|LGA| 13.33|     182|   70|1732.0|    1|        4.0|    3.0|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_km = StringIndexer(inputCol='carrier', outputCol='carrier_idx').fit(df_km).transform(df_km)\n",
    "df_km = StringIndexer(inputCol='org', outputCol='org_idx').fit(df_km).transform(df_km)\n",
    "df_km.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+-------------+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|carrier_idx|org_idx|            features|    org_dummy|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+-------------+\n",
      "| 10| 10|  1|     OO|ORD|  8.18|      51|   27| 253.0|    1|        2.0|    0.0|[10.0,10.0,1.0,2....|(7,[0],[1.0])|\n",
      "| 11| 22|  1|     OO|ORD|  7.17|     127|  -19|1188.0|    0|        2.0|    0.0|[11.0,22.0,1.0,2....|(7,[0],[1.0])|\n",
      "|  2| 14|  5|     B6|JFK| 21.17|     365|   60|3618.0|    1|        4.0|    2.0|[2.0,14.0,5.0,4.0...|(7,[2],[1.0])|\n",
      "|  5| 25|  3|     WN|SJC| 12.92|      85|   22| 621.0|    1|        3.0|    5.0|[5.0,25.0,3.0,3.0...|(7,[5],[1.0])|\n",
      "|  3| 28|  1|     B6|LGA| 13.33|     182|   70|1732.0|    1|        4.0|    3.0|[3.0,28.0,1.0,4.0...|(7,[3],[1.0])|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create One Hot Encoding for 'org'\n",
    "df_km = OneHotEncoder(inputCols=['org_idx'], outputCols=['org_dummy'], dropLast=True) \\\n",
    "                    .fit(df_km) \\\n",
    "                    .transform(df_km)\n",
    "df_km.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|delay|\n",
      "+--------------------+-----+\n",
      "|[10.0,10.0,1.0,2....|   27|\n",
      "|[11.0,22.0,1.0,2....|  -19|\n",
      "|[2.0,14.0,5.0,4.0...|   60|\n",
      "|[5.0,25.0,3.0,3.0...|   22|\n",
      "|[3.0,28.0,1.0,4.0...|   70|\n",
      "|[5.0,28.0,6.0,4.0...|   47|\n",
      "|[1.0,19.0,2.0,0.0...|  135|\n",
      "|[8.0,5.0,5.0,6.0,...|  -10|\n",
      "|[5.0,27.0,5.0,1.0...|  -11|\n",
      "|[8.0,20.0,6.0,4.0...|   20|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_km = VectorAssembler(\n",
    "    inputCols=['mon', 'dom', 'dow', 'carrier_idx', 'org_idx', 'km', 'depart', 'duration'],\n",
    "    outputCol='features'\n",
    ").transform(df_km)\n",
    "\n",
    "df_km.select('features', 'delay').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9921529213939193\n"
     ]
    }
   ],
   "source": [
    "# Divide into train and test sets\n",
    "df_km_train, df_km_test = df_km.randomSplit([0.8, 0.2], seed=17)\n",
    "training_ratio = df_km_train.count() / df_km_test.count()\n",
    "print(training_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------------------------------+----------+\n",
      "|label|probability                             |prediction|\n",
      "+-----+----------------------------------------+----------+\n",
      "|1    |[0.5734357848518112,0.4265642151481888] |0.0       |\n",
      "|1    |[0.5734357848518112,0.4265642151481888] |0.0       |\n",
      "|0    |[0.37154355176634096,0.628456448233659] |1.0       |\n",
      "|1    |[0.37154355176634096,0.628456448233659] |1.0       |\n",
      "|0    |[0.47085201793721976,0.5291479820627802]|1.0       |\n",
      "+-----+----------------------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "decision_tree = DecisionTreeClassifier(featuresCol='features', labelCol='label')\n",
    "model_tree = decision_tree.fit(df_km_train)\n",
    "prediction = model_tree.transform(df_km_test)\n",
    "prediction.select('label', 'probability', 'prediction').show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+-----------------+--------------------+----------+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|carrier_idx|org_idx|            features|    rawPrediction|         probability|prediction|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+-----------------+--------------------+----------+\n",
      "|  0|  1|  2|     AA|JFK|  6.58|     230|   50|2570.0|    1|        1.0|    2.0|[0.0,1.0,2.0,1.0,...|  [2612.0,1943.0]|[0.57343578485181...|       0.0|\n",
      "|  0|  1|  2|     AA|LGA|   6.0|     240|   45|2235.0|    1|        1.0|    3.0|[0.0,1.0,2.0,1.0,...|  [2612.0,1943.0]|[0.57343578485181...|       0.0|\n",
      "|  0|  1|  2|     AA|LGA|  11.5|     195|  -11|1765.0|    0|        1.0|    3.0|[0.0,1.0,2.0,1.0,...|[35822.0,60592.0]|[0.37154355176634...|       1.0|\n",
      "|  0|  1|  2|     AA|LGA| 20.42|     185|   31|1765.0|    1|        1.0|    3.0|[0.0,1.0,2.0,1.0,...|[35822.0,60592.0]|[0.37154355176634...|       1.0|\n",
      "|  0|  1|  2|     AA|OGG| 18.08|     420|   -6|5972.0|    0|        1.0|    7.0|[0.0,1.0,2.0,1.0,...|  [2205.0,2478.0]|[0.47085201793721...|       1.0|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+-----------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0| 6856|\n",
      "|    0|       0.0|13598|\n",
      "|    1|       1.0|19259|\n",
      "|    0|       1.0|12026|\n",
      "+-----+----------+-----+\n",
      "\n",
      "0.635052861477802\n"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix\n",
    "prediction.groupby('label', 'prediction').count().show()\n",
    "TP = prediction.filter('label=1 AND label=prediction').count()\n",
    "TN = prediction.filter('label=0 AND label=prediction').count()\n",
    "FP = prediction.filter('label=0 AND label<>prediction').count()\n",
    "FN = prediction.filter('label=1 AND label<>prediction').count()\n",
    "\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------------------------------+----------+\n",
      "|label|probability                             |prediction|\n",
      "+-----+----------------------------------------+----------+\n",
      "|1    |[0.5567959243275945,0.44320407567240544]|0.0       |\n",
      "|1    |[0.5243884719960039,0.4756115280039961] |0.0       |\n",
      "|0    |[0.4542830437458366,0.5457169562541633] |1.0       |\n",
      "|1    |[0.3165134296412002,0.6834865703587998] |1.0       |\n",
      "|0    |[0.5764246565510142,0.42357534344898573]|0.0       |\n",
      "+-----+----------------------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_logreg = LogisticRegression(featuresCol='features', labelCol='label').fit(df_km_train)\n",
    "prediction_logreg = model_logreg.transform(df_km_test)\n",
    "prediction_logreg.select('label', 'probability', 'prediction').show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0| 9455|\n",
      "|    0|       0.0|14931|\n",
      "|    1|       1.0|16660|\n",
      "|    0|       1.0|10693|\n",
      "+-----+----------+-----+\n",
      "\n",
      "Accuracy: 0.6105838922282998\n"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix\n",
    "prediction_logreg.groupby('label', 'prediction').count().show()\n",
    "TP = prediction_logreg.filter('label=1 AND label=prediction').count()\n",
    "TN = prediction_logreg.filter('label=0 AND label=prediction').count()\n",
    "FP = prediction_logreg.filter('label=0 AND label<>prediction').count()\n",
    "FN = prediction_logreg.filter('label=1 AND label<>prediction').count()\n",
    "\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.61 | Recall: 0.64\n",
      "Weighted precision: 0.61\n",
      "AUC: 0.65\n"
     ]
    }
   ],
   "source": [
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "print(f\"Precision: {precision:.2f} | Recall: {recall:.2f}\")\n",
    "\n",
    "# Weighted precision\n",
    "multi_evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', \n",
    "                                                    labelCol='label', \n",
    "                                                    metricName='weightedPrecision')\n",
    "weighted_precision = multi_evaluator.evaluate(prediction_logreg)\n",
    "print(f\"Weighted precision: {weighted_precision:.2f}\")\n",
    "\n",
    "# AUC\n",
    "binary_evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction',\n",
    "                                                 labelCol='label', \n",
    "                                                 metricName='areaUnderROC')\n",
    "AUC = binary_evaluator.evaluate(prediction_logreg)\n",
    "print(f\"AUC: {AUC:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+-------------+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|carrier_idx|org_idx|            features|    org_dummy|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+-------------+\n",
      "| 10| 10|  1|     OO|ORD|  8.18|      51|   27| 253.0|    1|        2.0|    0.0|[10.0,10.0,1.0,2....|(7,[0],[1.0])|\n",
      "| 11| 22|  1|     OO|ORD|  7.17|     127|  -19|1188.0|    0|        2.0|    0.0|[11.0,22.0,1.0,2....|(7,[0],[1.0])|\n",
      "|  2| 14|  5|     B6|JFK| 21.17|     365|   60|3618.0|    1|        4.0|    2.0|[2.0,14.0,5.0,4.0...|(7,[2],[1.0])|\n",
      "|  5| 25|  3|     WN|SJC| 12.92|      85|   22| 621.0|    1|        3.0|    5.0|[5.0,25.0,3.0,3.0...|(7,[5],[1.0])|\n",
      "|  3| 28|  1|     B6|LGA| 13.33|     182|   70|1732.0|    1|        4.0|    3.0|[3.0,28.0,1.0,4.0...|(7,[3],[1.0])|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_km.show(5)\n",
    "df_regr = df_km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+-------------+-------------+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|carrier_idx|org_idx|            features|    org_dummy|depart_bucket|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+-------------+-------------+\n",
      "| 10| 10|  1|     OO|ORD|  8.18|      51|   27| 253.0|    1|        2.0|    0.0|[10.0,10.0,1.0,2....|(7,[0],[1.0])|          2.0|\n",
      "| 11| 22|  1|     OO|ORD|  7.17|     127|  -19|1188.0|    0|        2.0|    0.0|[11.0,22.0,1.0,2....|(7,[0],[1.0])|          2.0|\n",
      "|  2| 14|  5|     B6|JFK| 21.17|     365|   60|3618.0|    1|        4.0|    2.0|[2.0,14.0,5.0,4.0...|(7,[2],[1.0])|          7.0|\n",
      "|  5| 25|  3|     WN|SJC| 12.92|      85|   22| 621.0|    1|        3.0|    5.0|[5.0,25.0,3.0,3.0...|(7,[5],[1.0])|          4.0|\n",
      "|  3| 28|  1|     B6|LGA| 13.33|     182|   70|1732.0|    1|        4.0|    3.0|[3.0,28.0,1.0,4.0...|(7,[3],[1.0])|          4.0|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "buckets = Bucketizer(splits=[0.0, 3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0],\n",
    "                     inputCol='depart',\n",
    "                     outputCol='depart_bucket')\n",
    "df_regr = buckets.transform(df_regr)\n",
    "df_regr.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+-------------+-------------+-------------+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|carrier_idx|org_idx|            features|    org_dummy|depart_bucket| depart_dummy|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+-------------+-------------+-------------+\n",
      "| 10| 10|  1|     OO|ORD|  8.18|      51|   27| 253.0|    1|        2.0|    0.0|[10.0,10.0,1.0,2....|(7,[0],[1.0])|          2.0|(7,[2],[1.0])|\n",
      "| 11| 22|  1|     OO|ORD|  7.17|     127|  -19|1188.0|    0|        2.0|    0.0|[11.0,22.0,1.0,2....|(7,[0],[1.0])|          2.0|(7,[2],[1.0])|\n",
      "|  2| 14|  5|     B6|JFK| 21.17|     365|   60|3618.0|    1|        4.0|    2.0|[2.0,14.0,5.0,4.0...|(7,[2],[1.0])|          7.0|    (7,[],[])|\n",
      "|  5| 25|  3|     WN|SJC| 12.92|      85|   22| 621.0|    1|        3.0|    5.0|[5.0,25.0,3.0,3.0...|(7,[5],[1.0])|          4.0|(7,[4],[1.0])|\n",
      "|  3| 28|  1|     B6|LGA| 13.33|     182|   70|1732.0|    1|        4.0|    3.0|[3.0,28.0,1.0,4.0...|(7,[3],[1.0])|          4.0|(7,[4],[1.0])|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+-------------+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_regr = OneHotEncoder(inputCol='depart_bucket', outputCol='depart_dummy').fit(df_regr).transform(df_regr)\n",
    "df_regr.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- mon: integer (nullable = true)\n",
      " |-- dom: integer (nullable = true)\n",
      " |-- dow: integer (nullable = true)\n",
      " |-- carrier: string (nullable = true)\n",
      " |-- org: string (nullable = true)\n",
      " |-- depart: double (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- delay: integer (nullable = true)\n",
      " |-- km: double (nullable = true)\n",
      " |-- label: integer (nullable = false)\n",
      " |-- carrier_idx: double (nullable = false)\n",
      " |-- org_idx: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- org_dummy: vector (nullable = true)\n",
      " |-- depart_bucket: double (nullable = true)\n",
      " |-- depart_dummy: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_regr.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+-------------+-------------+-------------+--------------------+------------------+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|carrier_idx|org_idx|            features|    org_dummy|depart_bucket| depart_dummy|       features_regr|        prediction|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+-------------+-------------+-------------+--------------------+------------------+\n",
      "|  0|  1|  2|     AA|JFK| 14.92|     245|    6|2239.0|    0|        1.0|    2.0|[0.0,1.0,2.0,1.0,...|(7,[2],[1.0])|          4.0|(7,[4],[1.0])|(15,[0,3,12],[223...|233.31585741170153|\n",
      "|  0|  1|  2|     AA|LGA|   6.0|     240|   45|2235.0|    1|        1.0|    3.0|[0.0,1.0,2.0,1.0,...|(7,[3],[1.0])|          2.0|(7,[2],[1.0])|(15,[0,4,10],[223...|226.48855602014007|\n",
      "|  0|  1|  2|     AA|LGA| 15.33|     190|    4|1765.0|    0|        1.0|    3.0|[0.0,1.0,2.0,1.0,...|(7,[3],[1.0])|          5.0|(7,[5],[1.0])|(15,[0,4,13],[176...|196.39920174475776|\n",
      "|  0|  1|  2|     AA|LGA| 15.58|     160|   20|1180.0|    1|        1.0|    3.0|[0.0,1.0,2.0,1.0,...|(7,[3],[1.0])|          5.0|(7,[5],[1.0])|(15,[0,4,13],[118...| 152.9381145461736|\n",
      "|  0|  1|  2|     AA|LGA| 19.75|     170|   -1|1427.0|    0|        1.0|    3.0|[0.0,1.0,2.0,1.0,...|(7,[3],[1.0])|          6.0|(7,[6],[1.0])|(15,[0,4,14],[142...|171.31016407363595|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+-------------+-------------+-------------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_regr = VectorAssembler(inputCols=['km', 'org_dummy', 'depart_dummy'], outputCol='features_regr').transform(df_regr)\n",
    "df_regr_train, df_regr_test = df_regr.randomSplit([0.8, 0.2], seed=123)\n",
    "prediction_model = LinearRegression(featuresCol='features_regr', labelCol='duration').fit(df_regr_train)\n",
    "prediction = prediction_model.transform(df_regr_test)\n",
    "prediction.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174.5781016318243\n"
     ]
    }
   ],
   "source": [
    "rmse = RegressionEvaluator(predictionCol='prediction', labelCol='label', metricName='rmse').evaluate(prediction)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 10.132522248072398\n",
      "Coefficients: [0.07429245674971649,27.30668249486161,20.1718880481367,51.905644634781815,46.04651215996389,15.243799792732002,17.44111102148055,17.66400952456524,-14.353146739270645,0.7997661451820286,4.265880776487429,7.2705918137934145,4.9368798662321005,9.093981173471848,9.115793883754197]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Intercept: {prediction_model.intercept}\")\n",
    "print(f\"Coefficients: {prediction_model.coefficients}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = r\"C:\\Users\\se.vi.dmitriev\\Downloads\\DS Materials\\scripts\\SMSSpamCollection\"\n",
    "schema = StructType([\n",
    "    StructField('label', StringType()),\n",
    "    StructField('text', StringType())\n",
    "])\n",
    "\n",
    "df = spark.read.csv(path, schema=schema, sep='\\t', header=False, inferSchema=True, nullValue='NA')\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|                text|\n",
      "+-----+--------------------+\n",
      "|    0|Go until jurong p...|\n",
      "|    0|Ok lar... Joking ...|\n",
      "|    1|Free entry in 2 a...|\n",
      "|    0|U dun say so earl...|\n",
      "|    0|Nah I don't think...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('label', F.when(df['label']=='ham', 0).otherwise(1))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+\n",
      "|label|                text|              tokens|               words|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "|    0|Go until jurong p...|Go until jurong p...|[go, until, juron...|\n",
      "|    0|Ok lar... Joking ...|Ok lar Joking wif...|[ok, lar, joking,...|\n",
      "|    1|Free entry in 2 a...|Free entry in a w...|[free, entry, in,...|\n",
      "|    0|U dun say so earl...|U dun say so earl...|[u, dun, say, so,...|\n",
      "|    0|Nah I don't think...|Nah I don't think...|[nah, i, don't, t...|\n",
      "|    1|FreeMsg Hey there...|FreeMsg Hey there...|[freemsg, hey, th...|\n",
      "|    0|Even my brother i...|Even my brother i...|[even, my, brothe...|\n",
      "|    0|As per your reque...|As per your reque...|[as, per, your, r...|\n",
      "|    1|WINNER!! As a val...|WINNER As a value...|[winner, as, a, v...|\n",
      "|    1|Had your mobile 1...|Had your mobile m...|[had, your, mobil...|\n",
      "|    0|I'm gonna be home...|I'm gonna be home...|[i'm, gonna, be, ...|\n",
      "|    1|SIX chances to wi...|SIX chances to wi...|[six, chances, to...|\n",
      "|    1|URGENT! You have ...|URGENT You have w...|[urgent, you, hav...|\n",
      "|    0|I've been searchi...|I've been searchi...|[i've, been, sear...|\n",
      "|    0|I HAVE A DATE ON ...|I HAVE A DATE ON ...|[i, have, a, date...|\n",
      "|    1|XXXMobileMovieClu...|XXXMobileMovieClu...|[xxxmobilemoviecl...|\n",
      "|    0|Oh k...i'm watchi...|Oh k i'm watching...|[oh, k, i'm, watc...|\n",
      "|    0|Eh u remember how...|Eh u remember how...|[eh, u, remember,...|\n",
      "|    0|Fine if thats th...|Fine if thats th...|[fine, if, thats...|\n",
      "|    1|England v Macedon...|England v Macedon...|[england, v, mace...|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_prep = df.withColumn('tokens', regexp_replace(df['text'], '[_():;,.!?\\\\-]', ' '))\n",
    "df_prep = df_prep.withColumn('tokens', regexp_replace(df_prep['tokens'], '\\d+', ' '))\n",
    "# Merge multiple spaces\n",
    "df_prep = df_prep.withColumn('tokens', regexp_replace(df_prep['tokens'], '\\s+', ' '))\n",
    "df_prep = Tokenizer(inputCol='tokens', outputCol='words').transform(df_prep)\n",
    "df_prep.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|label|                text|              tokens|               words|       words_cleaned|          words_hash|            features|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|    0|Go until jurong p...|Go until jurong p...|[go, until, juron...|[go, jurong, poin...|(1024,[12,171,191...|(1024,[12,171,191...|\n",
      "|    0|Ok lar... Joking ...|Ok lar Joking wif...|[ok, lar, joking,...|[ok, lar, joking,...|(1024,[3,493,565,...|(1024,[3,493,565,...|\n",
      "|    1|Free entry in 2 a...|Free entry in a w...|[free, entry, in,...|[free, entry, wkl...|(1024,[16,24,35,5...|(1024,[16,24,35,5...|\n",
      "|    0|U dun say so earl...|U dun say so earl...|[u, dun, say, so,...|[u, dun, say, ear...|(1024,[44,168,210...|(1024,[44,168,210...|\n",
      "|    0|Nah I don't think...|Nah I don't think...|[nah, i, don't, t...|[nah, think, goes...|(1024,[14,364,709...|(1024,[14,364,709...|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove stop words\n",
    "df_prep = StopWordsRemover(inputCol='words', outputCol='words_cleaned').transform(df_prep)\n",
    "df_prep = HashingTF(numFeatures=1024, inputCol='words_cleaned', outputCol='words_hash').transform(df_prep)\n",
    "tf_idf = IDF(inputCol='words_hash', outputCol='features').fit(df_prep).transform(df_prep)\n",
    "tf_idf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted precision: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "tf_idf_train, tf_idf_test = tf_idf.randomSplit([0.8, 0.2], seed=123)\n",
    "\n",
    "# Train and evaluate model\n",
    "predict_spam = LogisticRegression(featuresCol='features', labelCol='label').fit(tf_idf_train).transform(tf_idf_test)\n",
    "weighted_precision = MulticlassClassificationEvaluator(predictionCol='prediction', \n",
    "                                                       labelCol='label', \n",
    "                                                       metricName='weightedPrecision') \\\n",
    "                                                    .evaluate(predict_spam)\n",
    "print(f\"Weighted precision: {weighted_precision:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    0|       0.0|  942|\n",
      "|    0|       1.0|   25|\n",
      "|    1|       1.0|  129|\n",
      "|    1|       0.0|   17|\n",
      "+-----+----------+-----+\n",
      "\n",
      "Precision: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Calculate confusion matrix\n",
    "predict_spam.groupby('label', 'prediction').count().show()\n",
    "TP = predict_spam.filter('label=1 AND label=prediction').count()\n",
    "FP = predict_spam.filter('label=0 AND label<>prediction').count()\n",
    "precision = TP / (TP + FP)\n",
    "print(f\"Precision: {precision:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terminate the session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
