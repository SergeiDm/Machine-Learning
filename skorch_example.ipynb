{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from torch import nn, optim\n",
    "\n",
    "from skorch.dataset import CVSplit\n",
    "from skorch.callbacks import EpochScoring\n",
    "from skorch.classifier import NeuralNetClassifier\n",
    "from skorch.net import NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type X: float32\n",
      "Type y: int64\n"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=20,\n",
    "                           n_informative=10, n_classes=3,\n",
    "                           random_state=123)\n",
    "\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.int64)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, stratify=y, train_size=0.8)\n",
    "print(f\"Type X: {X_train.dtype}\")\n",
    "print(f\"Type y: {y_train.dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    accuracy_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------------  ------------  -----------  ------------  ------\n",
      "      1            \u001b[36m0.3103\u001b[0m        \u001b[32m1.1075\u001b[0m       \u001b[35m0.3833\u001b[0m        \u001b[31m1.0779\u001b[0m  0.0411\n",
      "      2            \u001b[36m0.4809\u001b[0m        \u001b[32m1.0574\u001b[0m       \u001b[35m0.5333\u001b[0m        \u001b[31m1.0481\u001b[0m  0.0361\n",
      "      3            \u001b[36m0.5588\u001b[0m        \u001b[32m1.0288\u001b[0m       \u001b[35m0.5667\u001b[0m        \u001b[31m1.0235\u001b[0m  0.0356\n",
      "      4            0.5529        \u001b[32m1.0006\u001b[0m       \u001b[35m0.6000\u001b[0m        \u001b[31m0.9996\u001b[0m  0.0351\n",
      "      5            \u001b[36m0.6132\u001b[0m        \u001b[32m0.9743\u001b[0m       0.5667        \u001b[31m0.9746\u001b[0m  0.0341\n",
      "      6            0.6088        \u001b[32m0.9456\u001b[0m       0.5583        \u001b[31m0.9480\u001b[0m  0.0351\n",
      "      7            \u001b[36m0.6191\u001b[0m        \u001b[32m0.9174\u001b[0m       0.5417        \u001b[31m0.9219\u001b[0m  0.0321\n",
      "      8            \u001b[36m0.6412\u001b[0m        \u001b[32m0.8785\u001b[0m       0.5500        \u001b[31m0.8956\u001b[0m  0.0361\n",
      "      9            \u001b[36m0.6485\u001b[0m        \u001b[32m0.8507\u001b[0m       0.5833        \u001b[31m0.8698\u001b[0m  0.0326\n",
      "     10            \u001b[36m0.6735\u001b[0m        \u001b[32m0.8218\u001b[0m       \u001b[35m0.6167\u001b[0m        \u001b[31m0.8450\u001b[0m  0.0336\n",
      "     11            \u001b[36m0.6794\u001b[0m        \u001b[32m0.7908\u001b[0m       \u001b[35m0.6250\u001b[0m        \u001b[31m0.8225\u001b[0m  0.0346\n",
      "     12            \u001b[36m0.7059\u001b[0m        \u001b[32m0.7637\u001b[0m       \u001b[35m0.6333\u001b[0m        \u001b[31m0.8029\u001b[0m  0.0361\n",
      "     13            0.7044        \u001b[32m0.7467\u001b[0m       \u001b[35m0.6417\u001b[0m        \u001b[31m0.7863\u001b[0m  0.0346\n",
      "     14            \u001b[36m0.7221\u001b[0m        \u001b[32m0.7176\u001b[0m       \u001b[35m0.6667\u001b[0m        \u001b[31m0.7693\u001b[0m  0.0356\n",
      "     15            \u001b[36m0.7250\u001b[0m        \u001b[32m0.6968\u001b[0m       \u001b[35m0.6750\u001b[0m        \u001b[31m0.7525\u001b[0m  0.0356\n",
      "     16            \u001b[36m0.7426\u001b[0m        \u001b[32m0.6664\u001b[0m       \u001b[35m0.7000\u001b[0m        \u001b[31m0.7372\u001b[0m  0.0356\n",
      "     17            \u001b[36m0.7485\u001b[0m        \u001b[32m0.6497\u001b[0m       \u001b[35m0.7083\u001b[0m        \u001b[31m0.7229\u001b[0m  0.0316\n",
      "     18            \u001b[36m0.7721\u001b[0m        \u001b[32m0.6128\u001b[0m       \u001b[35m0.7167\u001b[0m        \u001b[31m0.7078\u001b[0m  0.0341\n",
      "     19            0.7353        0.6277       \u001b[35m0.7333\u001b[0m        \u001b[31m0.6928\u001b[0m  0.0376\n",
      "     20            \u001b[36m0.7824\u001b[0m        \u001b[32m0.5823\u001b[0m       0.7250        \u001b[31m0.6834\u001b[0m  0.0336\n",
      "     21            0.7676        0.5897       \u001b[35m0.7500\u001b[0m        \u001b[31m0.6736\u001b[0m  0.0386\n",
      "     22            0.7588        \u001b[32m0.5822\u001b[0m       0.7500        \u001b[31m0.6572\u001b[0m  0.0391\n",
      "     23            \u001b[36m0.7882\u001b[0m        \u001b[32m0.5627\u001b[0m       0.7500        \u001b[31m0.6415\u001b[0m  0.0416\n",
      "     24            0.7794        \u001b[32m0.5476\u001b[0m       \u001b[35m0.7667\u001b[0m        \u001b[31m0.6286\u001b[0m  0.0356\n",
      "     25            \u001b[36m0.7897\u001b[0m        \u001b[32m0.5368\u001b[0m       \u001b[35m0.7750\u001b[0m        \u001b[31m0.6191\u001b[0m  0.0356\n"
     ]
    }
   ],
   "source": [
    "class NetClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_units=64):\n",
    "        super(NetClassifier, self).__init__()\n",
    "        self.num_units = num_units\n",
    "        \n",
    "        self.linear = nn.Linear(20, self.num_units)\n",
    "        self.linear2 = nn.Linear(self.num_units, 32)\n",
    "        self.linear3 = nn.Linear(32, 3)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = F.softmax(self.linear3(x), dim=1)\n",
    "        return x\n",
    "\n",
    "    \n",
    "acc_train = EpochScoring(scoring=accuracy_score, lower_is_better=False, on_train=True)\n",
    "acc_valid = EpochScoring(scoring=accuracy_score, lower_is_better=False, on_train=False)\n",
    "    \n",
    "net = NeuralNetClassifier(\n",
    "    module = NetClassifier,\n",
    "    #module__num_units = 54,\n",
    "    criterion=nn.NLLLoss,\n",
    "    optimizer=optim.Adam,\n",
    "    #optimizer__lr=1e-3,\n",
    "    lr=1e-3,\n",
    "    max_epochs=25,\n",
    "    device='cuda',\n",
    "    train_split=CVSplit(cv=0.15, stratified=True),\n",
    "    callbacks=[acc_train]\n",
    ")\n",
    "\n",
    "net.fit(X_train, y_train)\n",
    "y_class = net.predict(X_test)\n",
    "y_prob = net.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 2, 1, 1, 0, 2, 0, 2, 0, 0, 2, 0, 1, 2, 0, 1, 1, 1, 2, 0,\n",
       "       2, 2, 1, 1, 0, 2, 2, 2, 0, 1, 2, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       2, 2, 1, 2, 0, 0, 1, 2, 1, 0, 2, 0, 2, 1, 0, 1, 1, 2, 2, 0, 2, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 2, 1, 0, 0, 0, 1, 0, 2, 1, 2, 0, 0, 0, 1, 0,\n",
       "       1, 2, 2, 0, 1, 0, 2, 0, 0, 1, 0, 2, 2, 2, 1, 0, 0, 2, 1, 1, 0, 1,\n",
       "       0, 0, 1, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 2,\n",
       "       0, 1, 0, 1, 2, 2, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "       2, 2, 2, 2, 2, 1, 0, 2, 2, 2, 0, 2, 0, 2, 0, 0, 2, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 2, 1, 2, 1, 0, 2, 2, 0, 0, 0, 0, 1, 2, 0, 1, 2, 2,\n",
       "       2, 1], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.91190708e-01, 5.14783897e-02, 5.73309213e-02],\n",
       "       [7.14790165e-01, 1.87224895e-01, 9.79849398e-02],\n",
       "       [1.29795969e-01, 5.23964942e-01, 3.46239090e-01],\n",
       "       [2.42265776e-01, 3.26228857e-01, 4.31505442e-01],\n",
       "       [1.89428613e-01, 7.90573239e-01, 1.99981071e-02],\n",
       "       [2.36641631e-01, 5.70246994e-01, 1.93111360e-01],\n",
       "       [7.59905636e-01, 2.05117185e-02, 2.19582722e-01],\n",
       "       [1.92739591e-01, 2.07736343e-03, 8.05182993e-01],\n",
       "       [7.02628613e-01, 1.33170620e-01, 1.64200738e-01],\n",
       "       [3.58929396e-01, 3.43587361e-02, 6.06711864e-01],\n",
       "       [6.05406523e-01, 7.82932267e-02, 3.16300303e-01],\n",
       "       [6.38577461e-01, 1.32435396e-01, 2.28987187e-01],\n",
       "       [3.38282287e-02, 2.22261343e-03, 9.63949084e-01],\n",
       "       [8.48609984e-01, 9.11165550e-02, 6.02733940e-02],\n",
       "       [5.54128364e-02, 8.85331213e-01, 5.92559539e-02],\n",
       "       [3.87716182e-02, 1.19336978e-01, 8.41891468e-01],\n",
       "       [5.08691430e-01, 4.55509275e-02, 4.45757687e-01],\n",
       "       [5.54309860e-02, 7.53975034e-01, 1.90593943e-01],\n",
       "       [5.38669266e-02, 9.43060160e-01, 3.07290489e-03],\n",
       "       [7.65739083e-02, 8.70433867e-01, 5.29921912e-02],\n",
       "       [1.90128669e-01, 5.71787264e-03, 8.04153383e-01],\n",
       "       [4.78714377e-01, 4.05398846e-01, 1.15886785e-01],\n",
       "       [1.14296123e-01, 4.52473536e-02, 8.40456545e-01],\n",
       "       [3.45670134e-02, 1.48486465e-01, 8.16946447e-01],\n",
       "       [5.03456518e-02, 9.35945153e-01, 1.37091940e-02],\n",
       "       [4.82273102e-01, 4.87928540e-01, 2.97982823e-02],\n",
       "       [6.49767280e-01, 1.51689902e-01, 1.98542789e-01],\n",
       "       [1.88847501e-02, 3.64228189e-02, 9.44692433e-01],\n",
       "       [2.72586852e-01, 9.46795046e-02, 6.32733643e-01],\n",
       "       [2.20984057e-01, 2.23847516e-02, 7.56631196e-01],\n",
       "       [3.42846185e-01, 3.38894218e-01, 3.18259627e-01],\n",
       "       [1.77710593e-01, 6.56215310e-01, 1.66074097e-01],\n",
       "       [2.29886755e-01, 2.12051675e-01, 5.58061600e-01],\n",
       "       [9.32210922e-01, 3.91185880e-02, 2.86705606e-02],\n",
       "       [7.01419950e-01, 2.12155521e-01, 8.64244998e-02],\n",
       "       [2.06156418e-01, 6.91452324e-01, 1.02391325e-01],\n",
       "       [4.77288723e-01, 1.04636230e-01, 4.18075114e-01],\n",
       "       [1.77547857e-01, 7.96446085e-01, 2.60060951e-02],\n",
       "       [5.67466259e-01, 3.11995208e-01, 1.20538510e-01],\n",
       "       [1.04692042e-01, 7.74546862e-01, 1.20761111e-01],\n",
       "       [4.18405592e-01, 3.82392883e-01, 1.99201494e-01],\n",
       "       [6.22413993e-01, 1.02638833e-01, 2.74947166e-01],\n",
       "       [5.91486871e-01, 2.13992447e-01, 1.94520667e-01],\n",
       "       [9.46907923e-02, 8.70989323e-01, 3.43198366e-02],\n",
       "       [1.59790814e-01, 5.77396154e-02, 7.82469630e-01],\n",
       "       [2.60226458e-01, 3.17191631e-01, 4.22581881e-01],\n",
       "       [4.32591259e-01, 5.13950646e-01, 5.34580462e-02],\n",
       "       [3.19642350e-02, 3.84302810e-03, 9.64192748e-01],\n",
       "       [8.03746819e-01, 8.22136761e-04, 1.95431069e-01],\n",
       "       [5.47505379e-01, 3.10167372e-01, 1.42327249e-01],\n",
       "       [4.42135707e-03, 9.94586229e-01, 9.92349815e-04],\n",
       "       [1.11981556e-01, 3.77608806e-01, 5.10409594e-01],\n",
       "       [3.03630829e-01, 5.59742749e-01, 1.36626467e-01],\n",
       "       [4.15710360e-01, 2.02319071e-01, 3.81970584e-01],\n",
       "       [2.75107622e-01, 4.73196171e-02, 6.77572787e-01],\n",
       "       [8.72084618e-01, 3.38556767e-02, 9.40596834e-02],\n",
       "       [2.15971738e-01, 1.73087511e-03, 7.82297432e-01],\n",
       "       [4.35070135e-02, 9.32799399e-01, 2.36936081e-02],\n",
       "       [8.33699226e-01, 1.05801523e-02, 1.55720562e-01],\n",
       "       [9.34975669e-02, 8.02083671e-01, 1.04418755e-01],\n",
       "       [1.14100538e-01, 6.65023446e-01, 2.20875978e-01],\n",
       "       [1.83206331e-02, 4.85555409e-03, 9.76823747e-01],\n",
       "       [4.31194872e-01, 7.53871277e-02, 4.93418038e-01],\n",
       "       [6.58531666e-01, 1.96645066e-01, 1.44823283e-01],\n",
       "       [1.37594854e-02, 1.48806011e-03, 9.84752476e-01],\n",
       "       [4.47317421e-01, 5.04669249e-01, 4.80133370e-02],\n",
       "       [7.91706681e-01, 2.37559676e-02, 1.84537351e-01],\n",
       "       [4.55754809e-02, 9.38967586e-01, 1.54569102e-02],\n",
       "       [4.95216221e-01, 5.02378307e-02, 4.54545945e-01],\n",
       "       [7.62744009e-01, 1.89101905e-01, 4.81541418e-02],\n",
       "       [8.87098670e-01, 6.97283447e-02, 4.31730226e-02],\n",
       "       [1.77623183e-01, 7.49977112e-01, 7.23997131e-02],\n",
       "       [5.86497426e-01, 1.82514384e-01, 2.30988234e-01],\n",
       "       [3.42457980e-01, 7.63239339e-02, 5.81218123e-01],\n",
       "       [2.99833924e-01, 3.82049620e-01, 3.18116486e-01],\n",
       "       [7.52344131e-01, 1.18818350e-01, 1.28837451e-01],\n",
       "       [7.47110069e-01, 5.60519621e-02, 1.96837947e-01],\n",
       "       [5.52906156e-01, 6.46222010e-02, 3.82471621e-01],\n",
       "       [8.01344067e-02, 9.10308182e-01, 9.55737662e-03],\n",
       "       [7.71422982e-01, 1.27330482e-01, 1.01246491e-01],\n",
       "       [1.74888745e-01, 1.31128943e-02, 8.11998367e-01],\n",
       "       [6.05227165e-02, 9.28402245e-01, 1.10751046e-02],\n",
       "       [3.55690002e-01, 1.50874211e-02, 6.29222572e-01],\n",
       "       [7.54222870e-01, 1.23178169e-01, 1.22598931e-01],\n",
       "       [6.30499065e-01, 1.01419270e-01, 2.68081665e-01],\n",
       "       [5.83351374e-01, 1.19213000e-01, 2.97435582e-01],\n",
       "       [1.54235497e-01, 5.42772412e-01, 3.02992076e-01],\n",
       "       [8.52420449e-01, 2.96709891e-02, 1.17908582e-01],\n",
       "       [1.12783529e-01, 8.52241516e-01, 3.49749327e-02],\n",
       "       [3.46403807e-01, 1.58745572e-02, 6.37721717e-01],\n",
       "       [3.85702938e-01, 1.49432912e-01, 4.64864194e-01],\n",
       "       [5.78555226e-01, 3.54720056e-01, 6.67247027e-02],\n",
       "       [1.15330108e-01, 8.43255401e-01, 4.14144546e-02],\n",
       "       [4.13371891e-01, 3.99201572e-01, 1.87426507e-01],\n",
       "       [3.63615483e-01, 6.81387931e-02, 5.68245709e-01],\n",
       "       [5.38230896e-01, 1.64591849e-01, 2.97177225e-01],\n",
       "       [5.64328432e-01, 3.79249752e-01, 5.64217716e-02],\n",
       "       [1.94304630e-01, 7.12925196e-01, 9.27701816e-02],\n",
       "       [7.44595289e-01, 2.10385635e-01, 4.50190678e-02],\n",
       "       [1.46120470e-02, 4.42969128e-02, 9.41091061e-01],\n",
       "       [1.84175521e-01, 7.89982080e-02, 7.36826241e-01],\n",
       "       [1.36815924e-02, 3.89086753e-02, 9.47409809e-01],\n",
       "       [2.61763543e-01, 7.37256050e-01, 9.80398734e-04],\n",
       "       [4.90366817e-01, 2.96719253e-01, 2.12913975e-01],\n",
       "       [8.01087320e-01, 1.00912027e-01, 9.80006531e-02],\n",
       "       [1.20850101e-01, 4.13031012e-01, 4.66118813e-01],\n",
       "       [1.60684958e-01, 8.08843076e-01, 3.04719135e-02],\n",
       "       [2.61518747e-01, 6.74172103e-01, 6.43091500e-02],\n",
       "       [6.18225455e-01, 1.31498486e-01, 2.50276029e-01],\n",
       "       [3.17263580e-03, 9.96701300e-01, 1.26022467e-04],\n",
       "       [3.79457086e-01, 2.93039054e-01, 3.27503800e-01],\n",
       "       [5.32634556e-01, 1.43229067e-01, 3.24136317e-01],\n",
       "       [1.42361626e-01, 8.24750245e-01, 3.28881666e-02],\n",
       "       [2.05365777e-01, 1.57150514e-02, 7.78919160e-01],\n",
       "       [3.55538517e-01, 5.40783703e-01, 1.03677779e-01],\n",
       "       [6.90256834e-01, 3.37597951e-02, 2.75983274e-01],\n",
       "       [8.10869277e-01, 1.27166547e-02, 1.76414087e-01],\n",
       "       [9.35692847e-01, 1.82304531e-02, 4.60766889e-02],\n",
       "       [5.85762411e-02, 7.53017783e-01, 1.88406006e-01],\n",
       "       [2.34360322e-01, 2.67243832e-01, 4.98395830e-01],\n",
       "       [5.75583637e-01, 3.85298342e-01, 3.91179770e-02],\n",
       "       [5.16961336e-01, 3.19472015e-01, 1.63566649e-01],\n",
       "       [5.73831856e-01, 3.65667433e-01, 6.05006739e-02],\n",
       "       [4.85101283e-01, 5.52620776e-02, 4.59636718e-01],\n",
       "       [7.68357635e-01, 2.06741661e-01, 2.49007810e-02],\n",
       "       [5.55823684e-01, 9.45486352e-02, 3.49627703e-01],\n",
       "       [2.09829032e-01, 6.80993795e-01, 1.09177224e-01],\n",
       "       [4.97381479e-01, 3.19430709e-01, 1.83187813e-01],\n",
       "       [1.17273740e-01, 1.76439345e-01, 7.06286848e-01],\n",
       "       [8.30868125e-01, 8.46164525e-02, 8.45154449e-02],\n",
       "       [1.67335451e-01, 3.44305903e-01, 4.88358617e-01],\n",
       "       [1.98555812e-01, 9.76133440e-03, 7.91682899e-01],\n",
       "       [5.96405923e-01, 2.37053066e-01, 1.66540980e-01],\n",
       "       [2.55541265e-01, 5.94369769e-01, 1.50088996e-01],\n",
       "       [8.53769481e-01, 6.52411953e-02, 8.09893459e-02],\n",
       "       [4.23890837e-02, 9.08620775e-01, 4.89901043e-02],\n",
       "       [1.33941546e-01, 1.52874634e-01, 7.13183880e-01],\n",
       "       [1.47199959e-01, 3.69882762e-01, 4.82917249e-01],\n",
       "       [5.77299774e-01, 2.40679264e-01, 1.82020932e-01],\n",
       "       [2.30107561e-01, 6.25142395e-01, 1.44749999e-01],\n",
       "       [9.98932570e-02, 8.84555995e-01, 1.55507335e-02],\n",
       "       [5.70713207e-02, 9.25437212e-01, 1.74914598e-02],\n",
       "       [5.50410487e-02, 8.89398396e-01, 5.55605888e-02],\n",
       "       [5.62906802e-01, 3.10438238e-02, 4.06049460e-01],\n",
       "       [6.61678845e-03, 9.91991341e-01, 1.39191013e-03],\n",
       "       [3.99547011e-01, 4.36086744e-01, 1.64366290e-01],\n",
       "       [2.23937765e-01, 7.00923800e-01, 7.51383975e-02],\n",
       "       [3.46548408e-01, 6.28988981e-01, 2.44626012e-02],\n",
       "       [2.10708417e-02, 9.72688198e-01, 6.24091132e-03],\n",
       "       [6.92380726e-01, 1.32706866e-01, 1.74912453e-01],\n",
       "       [2.19634488e-01, 7.37891316e-01, 4.24741879e-02],\n",
       "       [4.76901948e-01, 2.64331400e-01, 2.58766681e-01],\n",
       "       [8.74694288e-01, 1.20951692e-02, 1.13210522e-01],\n",
       "       [4.72993217e-02, 9.44099903e-01, 8.60078819e-03],\n",
       "       [3.23394716e-01, 1.22063331e-01, 5.54541945e-01],\n",
       "       [3.01631540e-01, 1.96959645e-01, 5.01408815e-01],\n",
       "       [1.30989760e-01, 3.82977694e-01, 4.86032605e-01],\n",
       "       [3.54630500e-01, 2.17553899e-01, 4.27815616e-01],\n",
       "       [2.20024735e-01, 7.61953997e-04, 7.79213250e-01],\n",
       "       [2.27500170e-01, 5.25320172e-01, 2.47179672e-01],\n",
       "       [3.99875879e-01, 3.38455796e-01, 2.61668354e-01],\n",
       "       [3.43839258e-01, 5.64149395e-03, 6.50519252e-01],\n",
       "       [1.40504166e-01, 1.45976737e-01, 7.13519096e-01],\n",
       "       [1.97435513e-01, 3.65584064e-03, 7.98908591e-01],\n",
       "       [8.26335073e-01, 1.61720701e-02, 1.57492921e-01],\n",
       "       [3.58616173e-01, 1.08107418e-01, 5.33276379e-01],\n",
       "       [9.43144262e-01, 3.05162538e-02, 2.63395049e-02],\n",
       "       [6.22519962e-02, 6.09519742e-02, 8.76796067e-01],\n",
       "       [6.33868277e-01, 7.58544132e-02, 2.90277332e-01],\n",
       "       [6.15055025e-01, 1.73398837e-01, 2.11546138e-01],\n",
       "       [1.28937447e-02, 1.19698944e-03, 9.85909283e-01],\n",
       "       [4.06456888e-02, 9.57235634e-01, 2.11870600e-03],\n",
       "       [1.79940045e-01, 5.26833355e-01, 2.93226600e-01],\n",
       "       [3.34307879e-01, 5.53127229e-01, 1.12564944e-01],\n",
       "       [1.57043263e-02, 9.82474267e-01, 1.82144425e-03],\n",
       "       [4.76834774e-01, 3.24498266e-01, 1.98667005e-01],\n",
       "       [4.40279335e-01, 3.24279040e-01, 2.35441580e-01],\n",
       "       [8.94716978e-02, 8.83712769e-01, 2.68155225e-02],\n",
       "       [8.25542510e-01, 3.35698724e-02, 1.40887558e-01],\n",
       "       [1.30709961e-01, 8.28485489e-01, 4.08044979e-02],\n",
       "       [2.29429767e-01, 4.38889265e-01, 3.31680983e-01],\n",
       "       [3.18918526e-01, 2.45643985e-02, 6.56517088e-01],\n",
       "       [2.60079265e-01, 6.13415241e-01, 1.26505479e-01],\n",
       "       [4.50649559e-02, 3.76867387e-03, 9.51166332e-01],\n",
       "       [1.16503961e-01, 6.36858284e-01, 2.46637806e-01],\n",
       "       [5.21879017e-01, 3.37752223e-01, 1.40368760e-01],\n",
       "       [3.09980094e-01, 2.00540125e-02, 6.69965923e-01],\n",
       "       [6.90195262e-02, 2.31379032e-01, 6.99601471e-01],\n",
       "       [5.42734206e-01, 2.84844816e-01, 1.72421068e-01],\n",
       "       [5.27022600e-01, 6.17739223e-02, 4.11203474e-01],\n",
       "       [8.96308362e-01, 6.68982789e-02, 3.67933884e-02],\n",
       "       [4.85916674e-01, 1.54670089e-01, 3.59413296e-01],\n",
       "       [1.29248172e-01, 8.62800062e-01, 7.95172341e-03],\n",
       "       [3.31115872e-01, 5.72907459e-03, 6.63155079e-01],\n",
       "       [6.36697233e-01, 2.13108718e-01, 1.50194034e-01],\n",
       "       [2.40730152e-01, 6.71210825e-01, 8.80590454e-02],\n",
       "       [2.31748089e-01, 3.14059943e-01, 4.54192042e-01],\n",
       "       [2.61775941e-01, 8.98334235e-02, 6.48390651e-01],\n",
       "       [5.90289906e-02, 2.63438225e-01, 6.77532792e-01],\n",
       "       [7.37297535e-02, 9.15846467e-01, 1.04237599e-02]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "Re-initializing optimizer because the following parameters were re-set: lr.\n",
      "  epoch    accuracy_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------------  ------------  -----------  ------------  ------\n",
      "      1            \u001b[36m0.3794\u001b[0m        \u001b[32m1.0921\u001b[0m       \u001b[35m0.5000\u001b[0m        \u001b[31m1.0707\u001b[0m  0.0582\n",
      "      2            \u001b[36m0.4559\u001b[0m        \u001b[32m1.0609\u001b[0m       \u001b[35m0.5750\u001b[0m        \u001b[31m1.0428\u001b[0m  0.0401\n",
      "      3            \u001b[36m0.5235\u001b[0m        \u001b[32m1.0251\u001b[0m       \u001b[35m0.5917\u001b[0m        \u001b[31m1.0151\u001b[0m  0.0356\n",
      "      4            \u001b[36m0.5529\u001b[0m        \u001b[32m0.9966\u001b[0m       \u001b[35m0.6167\u001b[0m        \u001b[31m0.9860\u001b[0m  0.0343\n",
      "      5            \u001b[36m0.5574\u001b[0m        \u001b[32m0.9623\u001b[0m       \u001b[35m0.6500\u001b[0m        \u001b[31m0.9553\u001b[0m  0.0396\n",
      "      6            \u001b[36m0.5882\u001b[0m        \u001b[32m0.9358\u001b[0m       0.6417        \u001b[31m0.9238\u001b[0m  0.0346\n",
      "      7            \u001b[36m0.5926\u001b[0m        \u001b[32m0.9066\u001b[0m       \u001b[35m0.6750\u001b[0m        \u001b[31m0.8918\u001b[0m  0.0321\n",
      "      8            \u001b[36m0.6088\u001b[0m        \u001b[32m0.8755\u001b[0m       \u001b[35m0.6833\u001b[0m        \u001b[31m0.8607\u001b[0m  0.0356\n",
      "      9            \u001b[36m0.6397\u001b[0m        \u001b[32m0.8483\u001b[0m       0.6833        \u001b[31m0.8310\u001b[0m  0.0381\n",
      "     10            \u001b[36m0.6426\u001b[0m        \u001b[32m0.8260\u001b[0m       \u001b[35m0.7000\u001b[0m        \u001b[31m0.8034\u001b[0m  0.0351\n",
      "     11            \u001b[36m0.6544\u001b[0m        \u001b[32m0.7995\u001b[0m       \u001b[35m0.7083\u001b[0m        \u001b[31m0.7786\u001b[0m  0.0331\n",
      "     12            0.6485        \u001b[32m0.7694\u001b[0m       0.7000        \u001b[31m0.7564\u001b[0m  0.0351\n",
      "     13            \u001b[36m0.6838\u001b[0m        \u001b[32m0.7499\u001b[0m       0.7083        \u001b[31m0.7336\u001b[0m  0.0341\n",
      "     14            0.6838        \u001b[32m0.7308\u001b[0m       0.7083        \u001b[31m0.7123\u001b[0m  0.0346\n",
      "     15            \u001b[36m0.6926\u001b[0m        \u001b[32m0.7072\u001b[0m       0.7083        \u001b[31m0.6947\u001b[0m  0.0326\n",
      "     16            0.6912        0.7105       0.7083        \u001b[31m0.6793\u001b[0m  0.0321\n",
      "     17            \u001b[36m0.7191\u001b[0m        \u001b[32m0.6910\u001b[0m       0.7083        \u001b[31m0.6653\u001b[0m  0.0326\n",
      "     18            0.6956        \u001b[32m0.6803\u001b[0m       \u001b[35m0.7167\u001b[0m        \u001b[31m0.6530\u001b[0m  0.0411\n",
      "     19            \u001b[36m0.7412\u001b[0m        \u001b[32m0.6454\u001b[0m       0.7167        \u001b[31m0.6422\u001b[0m  0.0376\n",
      "     20            0.7221        \u001b[32m0.6411\u001b[0m       0.7167        \u001b[31m0.6311\u001b[0m  0.0351\n",
      "     21            0.7265        \u001b[32m0.6213\u001b[0m       0.7167        \u001b[31m0.6197\u001b[0m  0.0371\n",
      "     22            \u001b[36m0.7456\u001b[0m        0.6299       \u001b[35m0.7500\u001b[0m        \u001b[31m0.6076\u001b[0m  0.0361\n",
      "     23            \u001b[36m0.7485\u001b[0m        0.6223       0.7417        \u001b[31m0.5976\u001b[0m  0.0341\n",
      "     24            \u001b[36m0.7735\u001b[0m        \u001b[32m0.5872\u001b[0m       0.7500        \u001b[31m0.5879\u001b[0m  0.0346\n",
      "     25            0.7559        0.5985       0.7417        \u001b[31m0.5763\u001b[0m  0.0391\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('net', net)\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_class = pipe.predict(X_test)\n",
    "y_prob = pipe.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['module',\n",
       " 'iterator_train',\n",
       " 'iterator_valid',\n",
       " 'optimizer',\n",
       " 'criterion',\n",
       " 'callbacks',\n",
       " 'dataset']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.prefixes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[CV] net__module__num_units=50 .......................................\n",
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "Re-initializing optimizer.\n",
      "  epoch    accuracy_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------------  ------------  -----------  ------------  ------\n",
      "      1            \u001b[36m0.3451\u001b[0m        \u001b[32m1.1052\u001b[0m       \u001b[35m0.3125\u001b[0m        \u001b[31m1.0943\u001b[0m  0.0317\n",
      "      2            \u001b[36m0.3982\u001b[0m        \u001b[32m1.0775\u001b[0m       \u001b[35m0.4250\u001b[0m        \u001b[31m1.0732\u001b[0m  0.0251\n",
      "      3            \u001b[36m0.4690\u001b[0m        \u001b[32m1.0531\u001b[0m       \u001b[35m0.4625\u001b[0m        \u001b[31m1.0542\u001b[0m  0.0221\n",
      "      4            \u001b[36m0.5221\u001b[0m        \u001b[32m1.0383\u001b[0m       \u001b[35m0.5125\u001b[0m        \u001b[31m1.0360\u001b[0m  0.0256\n",
      "      5            0.5177        \u001b[32m1.0239\u001b[0m       0.5125        \u001b[31m1.0187\u001b[0m  0.0241"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      6            \u001b[36m0.5310\u001b[0m        \u001b[32m1.0083\u001b[0m       \u001b[35m0.5250\u001b[0m        \u001b[31m1.0022\u001b[0m  0.0276\n",
      "      7            \u001b[36m0.5686\u001b[0m        \u001b[32m0.9847\u001b[0m       \u001b[35m0.5500\u001b[0m        \u001b[31m0.9865\u001b[0m  0.0231\n",
      "      8            0.5597        \u001b[32m0.9761\u001b[0m       \u001b[35m0.5875\u001b[0m        \u001b[31m0.9707\u001b[0m  0.0251\n",
      "      9            \u001b[36m0.5885\u001b[0m        \u001b[32m0.9507\u001b[0m       \u001b[35m0.6000\u001b[0m        \u001b[31m0.9563\u001b[0m  0.0261\n",
      "     10            \u001b[36m0.6195\u001b[0m        \u001b[32m0.9243\u001b[0m       \u001b[35m0.6250\u001b[0m        \u001b[31m0.9432\u001b[0m  0.0251\n",
      "     11            \u001b[36m0.6283\u001b[0m        \u001b[32m0.9185\u001b[0m       0.6250        \u001b[31m0.9317\u001b[0m  0.0231\n",
      "     12            \u001b[36m0.6438\u001b[0m        \u001b[32m0.8856\u001b[0m       \u001b[35m0.6375\u001b[0m        \u001b[31m0.9219\u001b[0m  0.0241\n",
      "     13            0.6173        \u001b[32m0.8762\u001b[0m       0.6375        \u001b[31m0.9127\u001b[0m  0.0231\n",
      "     14            \u001b[36m0.6482\u001b[0m        \u001b[32m0.8548\u001b[0m       0.6375        \u001b[31m0.9025\u001b[0m  0.0221\n",
      "     15            0.6350        \u001b[32m0.8450\u001b[0m       \u001b[35m0.6625\u001b[0m        \u001b[31m0.8915\u001b[0m  0.0226\n",
      "     16            0.6460        \u001b[32m0.8260\u001b[0m       0.6375        \u001b[31m0.8809\u001b[0m  0.0261\n",
      "     17            \u001b[36m0.6681\u001b[0m        \u001b[32m0.7979\u001b[0m       0.6375        \u001b[31m0.8726\u001b[0m  0.0206\n",
      "     18            0.6681        \u001b[32m0.7785\u001b[0m       0.6250        \u001b[31m0.8657\u001b[0m  0.0271\n",
      "     19            \u001b[36m0.6814\u001b[0m        \u001b[32m0.7583\u001b[0m       0.6375        \u001b[31m0.8587\u001b[0m  0.0251\n",
      "     20            \u001b[36m0.6858\u001b[0m        \u001b[32m0.7442\u001b[0m       0.6500        \u001b[31m0.8534\u001b[0m  0.0216\n",
      "     21            0.6814        \u001b[32m0.7335\u001b[0m       0.6500        \u001b[31m0.8448\u001b[0m  0.0261\n",
      "     22            0.6792        \u001b[32m0.7187\u001b[0m       0.6500        \u001b[31m0.8393\u001b[0m  0.0381\n",
      "     23            \u001b[36m0.7190\u001b[0m        \u001b[32m0.7105\u001b[0m       0.6500        \u001b[31m0.8377\u001b[0m  0.0251\n",
      "     24            0.7102        \u001b[32m0.6881\u001b[0m       0.6375        \u001b[31m0.8363\u001b[0m  0.0261\n",
      "     25            0.7058        0.6906       0.6375        \u001b[31m0.8350\u001b[0m  0.0236\n",
      "[CV] ........................ net__module__num_units=50, total=   0.8s\n",
      "[CV] net__module__num_units=50 .......................................\n",
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "Re-initializing optimizer.\n",
      "  epoch    accuracy_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------------  ------------  -----------  ------------  ------\n",
      "      1            \u001b[36m0.3091\u001b[0m        \u001b[32m1.1028\u001b[0m       \u001b[35m0.4250\u001b[0m        \u001b[31m1.0639\u001b[0m  0.0246\n",
      "      2            \u001b[36m0.3709\u001b[0m        \u001b[32m1.0727\u001b[0m       \u001b[35m0.5375\u001b[0m        \u001b[31m1.0418\u001b[0m  0.0241\n",
      "      3            \u001b[36m0.4768\u001b[0m        \u001b[32m1.0448\u001b[0m       \u001b[35m0.5750\u001b[0m        \u001b[31m1.0220\u001b[0m  0.0241\n",
      "      4            \u001b[36m0.5320\u001b[0m        \u001b[32m1.0213\u001b[0m       0.5250        \u001b[31m1.0036\u001b[0m  0.0241\n",
      "      5            \u001b[36m0.5408\u001b[0m        \u001b[32m0.9999\u001b[0m       0.5500        \u001b[31m0.9859\u001b[0m  0.0231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6            \u001b[36m0.5629\u001b[0m        \u001b[32m0.9761\u001b[0m       0.5625        \u001b[31m0.9683\u001b[0m  0.0241\n",
      "      7            \u001b[36m0.6115\u001b[0m        \u001b[32m0.9422\u001b[0m       0.5750        \u001b[31m0.9507\u001b[0m  0.0226\n",
      "      8            0.5982        \u001b[32m0.9270\u001b[0m       \u001b[35m0.6000\u001b[0m        \u001b[31m0.9330\u001b[0m  0.0261\n",
      "      9            0.6093        \u001b[32m0.9099\u001b[0m       \u001b[35m0.6250\u001b[0m        \u001b[31m0.9161\u001b[0m  0.0226\n",
      "     10            \u001b[36m0.6358\u001b[0m        \u001b[32m0.8868\u001b[0m       \u001b[35m0.6375\u001b[0m        \u001b[31m0.8993\u001b[0m  0.0216\n",
      "     11            0.6093        \u001b[32m0.8696\u001b[0m       0.6375        \u001b[31m0.8828\u001b[0m  0.0216\n",
      "     12            \u001b[36m0.6645\u001b[0m        \u001b[32m0.8553\u001b[0m       0.6375        \u001b[31m0.8665\u001b[0m  0.0256\n",
      "     13            0.6313        \u001b[32m0.8365\u001b[0m       0.6375        \u001b[31m0.8514\u001b[0m  0.0281\n",
      "     14            0.6534        \u001b[32m0.8102\u001b[0m       0.6375        \u001b[31m0.8369\u001b[0m  0.0246\n",
      "     15            \u001b[36m0.6667\u001b[0m        \u001b[32m0.7860\u001b[0m       \u001b[35m0.6500\u001b[0m        \u001b[31m0.8232\u001b[0m  0.0231\n",
      "     16            \u001b[36m0.6865\u001b[0m        \u001b[32m0.7687\u001b[0m       0.6375        \u001b[31m0.8098\u001b[0m  0.0261\n",
      "     17            0.6667        \u001b[32m0.7546\u001b[0m       0.6500        \u001b[31m0.7976\u001b[0m  0.0226\n",
      "     18            \u001b[36m0.6954\u001b[0m        \u001b[32m0.7447\u001b[0m       \u001b[35m0.6750\u001b[0m        \u001b[31m0.7867\u001b[0m  0.0256\n",
      "     19            \u001b[36m0.7108\u001b[0m        \u001b[32m0.7237\u001b[0m       \u001b[35m0.6875\u001b[0m        \u001b[31m0.7742\u001b[0m  0.0251\n",
      "     20            \u001b[36m0.7285\u001b[0m        \u001b[32m0.6947\u001b[0m       0.6875        \u001b[31m0.7608\u001b[0m  0.0261\n",
      "     21            0.6623        0.7004       \u001b[35m0.7000\u001b[0m        \u001b[31m0.7477\u001b[0m  0.0251\n",
      "     22            0.7020        \u001b[32m0.6894\u001b[0m       0.6875        \u001b[31m0.7347\u001b[0m  0.0256\n",
      "     23            0.6998        \u001b[32m0.6773\u001b[0m       0.7000        \u001b[31m0.7229\u001b[0m  0.0241\n",
      "     24            \u001b[36m0.7417\u001b[0m        \u001b[32m0.6535\u001b[0m       \u001b[35m0.7125\u001b[0m        \u001b[31m0.7125\u001b[0m  0.0246\n",
      "     25            0.7174        \u001b[32m0.6425\u001b[0m       0.7000        \u001b[31m0.7013\u001b[0m  0.0246\n",
      "[CV] ........................ net__module__num_units=50, total=   0.8s\n",
      "[CV] net__module__num_units=50 .......................................\n",
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "Re-initializing optimizer.\n",
      "  epoch    accuracy_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------------  ------------  -----------  ------------  ------\n",
      "      1            \u001b[36m0.3899\u001b[0m        \u001b[32m1.0819\u001b[0m       \u001b[35m0.4074\u001b[0m        \u001b[31m1.0579\u001b[0m  0.0206\n",
      "      2            \u001b[36m0.4317\u001b[0m        \u001b[32m1.0587\u001b[0m       \u001b[35m0.4938\u001b[0m        \u001b[31m1.0332\u001b[0m  0.0236\n",
      "      3            \u001b[36m0.4934\u001b[0m        \u001b[32m1.0298\u001b[0m       \u001b[35m0.5062\u001b[0m        \u001b[31m1.0120\u001b[0m  0.0246\n",
      "      4            \u001b[36m0.5242\u001b[0m        \u001b[32m1.0030\u001b[0m       \u001b[35m0.5556\u001b[0m        \u001b[31m0.9926\u001b[0m  0.0251\n",
      "      5            0.5110        \u001b[32m0.9916\u001b[0m       \u001b[35m0.5679\u001b[0m        \u001b[31m0.9747\u001b[0m  0.0241\n",
      "      6            \u001b[36m0.5330\u001b[0m        \u001b[32m0.9727\u001b[0m       \u001b[35m0.5926\u001b[0m        \u001b[31m0.9577\u001b[0m  0.0221\n",
      "      7            \u001b[36m0.5485\u001b[0m        \u001b[32m0.9544\u001b[0m       0.5926        \u001b[31m0.9414\u001b[0m  0.0231\n",
      "      8            0.5485        \u001b[32m0.9493\u001b[0m       0.5926        \u001b[31m0.9264\u001b[0m  0.0266\n",
      "      9            \u001b[36m0.5947\u001b[0m        \u001b[32m0.9169\u001b[0m       \u001b[35m0.6049\u001b[0m        \u001b[31m0.9118\u001b[0m  0.0216\n",
      "     10            0.5749        \u001b[32m0.9116\u001b[0m       \u001b[35m0.6173\u001b[0m        \u001b[31m0.8972\u001b[0m  0.0231\n",
      "     11            0.5793        \u001b[32m0.8938\u001b[0m       \u001b[35m0.6296\u001b[0m        \u001b[31m0.8828\u001b[0m  0.0236\n",
      "     12            \u001b[36m0.6211\u001b[0m        \u001b[32m0.8764\u001b[0m       0.6296        \u001b[31m0.8677\u001b[0m  0.0261\n",
      "     13            \u001b[36m0.6278\u001b[0m        \u001b[32m0.8575\u001b[0m       0.6173        \u001b[31m0.8528\u001b[0m  0.0251\n",
      "     14            0.6123        \u001b[32m0.8433\u001b[0m       \u001b[35m0.6420\u001b[0m        \u001b[31m0.8388\u001b[0m  0.0226\n",
      "     15            \u001b[36m0.6520\u001b[0m        \u001b[32m0.8199\u001b[0m       \u001b[35m0.6543\u001b[0m        \u001b[31m0.8246\u001b[0m  0.0231\n",
      "     16            \u001b[36m0.6564\u001b[0m        \u001b[32m0.8072\u001b[0m       \u001b[35m0.6667\u001b[0m        \u001b[31m0.8112\u001b[0m  0.0246\n",
      "     17            \u001b[36m0.6586\u001b[0m        \u001b[32m0.7937\u001b[0m       0.6667        \u001b[31m0.7986\u001b[0m  0.0226\n",
      "     18            \u001b[36m0.6806\u001b[0m        \u001b[32m0.7673\u001b[0m       \u001b[35m0.6790\u001b[0m        \u001b[31m0.7860\u001b[0m  0.0266\n",
      "     19            \u001b[36m0.6916\u001b[0m        \u001b[32m0.7531\u001b[0m       0.6790        \u001b[31m0.7732\u001b[0m  0.0256\n",
      "     20            \u001b[36m0.6960\u001b[0m        \u001b[32m0.7455\u001b[0m       \u001b[35m0.6914\u001b[0m        \u001b[31m0.7603\u001b[0m  0.0221\n",
      "     21            \u001b[36m0.7181\u001b[0m        \u001b[32m0.7075\u001b[0m       0.6914        \u001b[31m0.7476\u001b[0m  0.0231\n",
      "     22            0.6850        0.7292       0.6790        \u001b[31m0.7359\u001b[0m  0.0211\n",
      "     23            \u001b[36m0.7269\u001b[0m        \u001b[32m0.7003\u001b[0m       \u001b[35m0.7037\u001b[0m        \u001b[31m0.7257\u001b[0m  0.0276\n",
      "     24            0.7203        \u001b[32m0.6754\u001b[0m       0.6790        \u001b[31m0.7169\u001b[0m  0.0251\n",
      "     25            \u001b[36m0.7379\u001b[0m        \u001b[32m0.6617\u001b[0m       0.6914        \u001b[31m0.7079\u001b[0m  0.0221\n",
      "[CV] ........................ net__module__num_units=50, total=   0.8s\n",
      "[CV] net__module__num_units=60 .......................................\n",
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "Re-initializing optimizer.\n",
      "  epoch    accuracy_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------------  ------------  -----------  ------------  ------\n",
      "      1            \u001b[36m0.3252\u001b[0m        \u001b[32m1.1101\u001b[0m       \u001b[35m0.3125\u001b[0m        \u001b[31m1.1003\u001b[0m  0.0211\n",
      "      2            \u001b[36m0.4093\u001b[0m        \u001b[32m1.0888\u001b[0m       \u001b[35m0.4250\u001b[0m        \u001b[31m1.0837\u001b[0m  0.0216\n",
      "      3            \u001b[36m0.4513\u001b[0m        \u001b[32m1.0688\u001b[0m       \u001b[35m0.4500\u001b[0m        \u001b[31m1.0691\u001b[0m  0.0211\n",
      "      4            \u001b[36m0.5044\u001b[0m        \u001b[32m1.0503\u001b[0m       \u001b[35m0.4875\u001b[0m        \u001b[31m1.0554\u001b[0m  0.0216\n",
      "      5            \u001b[36m0.5133\u001b[0m        \u001b[32m1.0332\u001b[0m       \u001b[35m0.5250\u001b[0m        \u001b[31m1.0419\u001b[0m  0.0246\n",
      "      6            \u001b[36m0.5686\u001b[0m        \u001b[32m1.0139\u001b[0m       \u001b[35m0.5625\u001b[0m        \u001b[31m1.0278\u001b[0m  0.0231\n",
      "      7            0.5487        \u001b[32m1.0011\u001b[0m       \u001b[35m0.5875\u001b[0m        \u001b[31m1.0123\u001b[0m  0.0261\n",
      "      8            \u001b[36m0.6018\u001b[0m        \u001b[32m0.9713\u001b[0m       \u001b[35m0.6375\u001b[0m        \u001b[31m0.9953\u001b[0m  0.0246\n",
      "      9            \u001b[36m0.6150\u001b[0m        \u001b[32m0.9533\u001b[0m       \u001b[35m0.6625\u001b[0m        \u001b[31m0.9775\u001b[0m  0.0271\n",
      "     10            0.6040        \u001b[32m0.9366\u001b[0m       \u001b[35m0.6750\u001b[0m        \u001b[31m0.9596\u001b[0m  0.0221\n",
      "     11            \u001b[36m0.6372\u001b[0m        \u001b[32m0.9203\u001b[0m       0.6625        \u001b[31m0.9416\u001b[0m  0.0216\n",
      "     12            0.6350        \u001b[32m0.8949\u001b[0m       0.6500        \u001b[31m0.9241\u001b[0m  0.0236\n",
      "     13            0.6372        \u001b[32m0.8809\u001b[0m       0.6375        \u001b[31m0.9075\u001b[0m  0.0221\n",
      "     14            \u001b[36m0.6549\u001b[0m        \u001b[32m0.8408\u001b[0m       0.6250        \u001b[31m0.8920\u001b[0m  0.0391\n",
      "     15            \u001b[36m0.6615\u001b[0m        \u001b[32m0.8302\u001b[0m       0.6250        \u001b[31m0.8781\u001b[0m  0.0206\n",
      "     16            \u001b[36m0.6659\u001b[0m        \u001b[32m0.7997\u001b[0m       0.6250        \u001b[31m0.8650\u001b[0m  0.0261\n",
      "     17            \u001b[36m0.6681\u001b[0m        \u001b[32m0.7936\u001b[0m       0.6500        \u001b[31m0.8517\u001b[0m  0.0236\n",
      "     18            \u001b[36m0.6969\u001b[0m        \u001b[32m0.7820\u001b[0m       0.6500        \u001b[31m0.8388\u001b[0m  0.0251\n",
      "     19            0.6925        \u001b[32m0.7419\u001b[0m       0.6375        \u001b[31m0.8275\u001b[0m  0.0206\n",
      "     20            \u001b[36m0.7080\u001b[0m        \u001b[32m0.7373\u001b[0m       0.6375        \u001b[31m0.8172\u001b[0m  0.0261\n",
      "     21            0.7035        \u001b[32m0.7252\u001b[0m       0.6375        \u001b[31m0.8074\u001b[0m  0.0221\n",
      "     22            \u001b[36m0.7235\u001b[0m        \u001b[32m0.7068\u001b[0m       0.6500        \u001b[31m0.7981\u001b[0m  0.0221\n",
      "     23            0.7146        \u001b[32m0.6899\u001b[0m       0.6625        \u001b[31m0.7898\u001b[0m  0.0221\n",
      "     24            0.7124        0.6938       0.6750        \u001b[31m0.7815\u001b[0m  0.0226\n",
      "     25            \u001b[36m0.7301\u001b[0m        \u001b[32m0.6647\u001b[0m       0.6750        \u001b[31m0.7745\u001b[0m  0.0271\n",
      "[CV] ........................ net__module__num_units=60, total=   0.8s\n",
      "[CV] net__module__num_units=60 .......................................\n",
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "Re-initializing optimizer.\n",
      "  epoch    accuracy_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------------  ------------  -----------  ------------  ------\n",
      "      1            \u001b[36m0.3179\u001b[0m        \u001b[32m1.1134\u001b[0m       \u001b[35m0.3625\u001b[0m        \u001b[31m1.0865\u001b[0m  0.0226\n",
      "      2            \u001b[36m0.4260\u001b[0m        \u001b[32m1.0738\u001b[0m       \u001b[35m0.4125\u001b[0m        \u001b[31m1.0570\u001b[0m  0.0221\n",
      "      3            \u001b[36m0.4967\u001b[0m        \u001b[32m1.0456\u001b[0m       \u001b[35m0.4875\u001b[0m        \u001b[31m1.0336\u001b[0m  0.0201\n",
      "      4            \u001b[36m0.5453\u001b[0m        \u001b[32m1.0193\u001b[0m       0.4875        \u001b[31m1.0138\u001b[0m  0.0236\n",
      "      5            0.5254        \u001b[32m0.9936\u001b[0m       \u001b[35m0.5000\u001b[0m        \u001b[31m0.9960\u001b[0m  0.0206\n",
      "      6            \u001b[36m0.5717\u001b[0m        \u001b[32m0.9751\u001b[0m       \u001b[35m0.5125\u001b[0m        \u001b[31m0.9794\u001b[0m  0.0221\n",
      "      7            \u001b[36m0.5784\u001b[0m        \u001b[32m0.9536\u001b[0m       0.5125        \u001b[31m0.9632\u001b[0m  0.0221\n",
      "      8            \u001b[36m0.5982\u001b[0m        \u001b[32m0.9319\u001b[0m       \u001b[35m0.5250\u001b[0m        \u001b[31m0.9471\u001b[0m  0.0246\n",
      "      9            \u001b[36m0.6071\u001b[0m        \u001b[32m0.9084\u001b[0m       0.5250        \u001b[31m0.9315\u001b[0m  0.0201\n",
      "     10            \u001b[36m0.6247\u001b[0m        \u001b[32m0.8925\u001b[0m       \u001b[35m0.5375\u001b[0m        \u001b[31m0.9169\u001b[0m  0.0256\n",
      "     11            \u001b[36m0.6645\u001b[0m        \u001b[32m0.8688\u001b[0m       \u001b[35m0.5500\u001b[0m        \u001b[31m0.9025\u001b[0m  0.0261\n",
      "     12            0.6490        \u001b[32m0.8456\u001b[0m       \u001b[35m0.5875\u001b[0m        \u001b[31m0.8890\u001b[0m  0.0276\n",
      "     13            0.6490        \u001b[32m0.8218\u001b[0m       \u001b[35m0.6000\u001b[0m        \u001b[31m0.8761\u001b[0m  0.0261\n",
      "     14            \u001b[36m0.6843\u001b[0m        \u001b[32m0.7954\u001b[0m       \u001b[35m0.6125\u001b[0m        \u001b[31m0.8639\u001b[0m  0.0211\n",
      "     15            0.6733        \u001b[32m0.7787\u001b[0m       0.6125        \u001b[31m0.8526\u001b[0m  0.0221\n",
      "     16            0.6667        \u001b[32m0.7601\u001b[0m       0.6125        \u001b[31m0.8421\u001b[0m  0.0216\n",
      "     17            0.6755        \u001b[32m0.7512\u001b[0m       0.6000        \u001b[31m0.8315\u001b[0m  0.0251\n",
      "     18            \u001b[36m0.6976\u001b[0m        \u001b[32m0.7314\u001b[0m       \u001b[35m0.6250\u001b[0m        \u001b[31m0.8207\u001b[0m  0.0226\n",
      "     19            \u001b[36m0.7196\u001b[0m        \u001b[32m0.7122\u001b[0m       \u001b[35m0.6375\u001b[0m        \u001b[31m0.8096\u001b[0m  0.0231\n",
      "     20            0.7064        \u001b[32m0.6888\u001b[0m       0.6250        \u001b[31m0.7994\u001b[0m  0.0226\n",
      "     21            0.7086        \u001b[32m0.6848\u001b[0m       0.6250        \u001b[31m0.7894\u001b[0m  0.0216\n",
      "     22            \u001b[36m0.7307\u001b[0m        \u001b[32m0.6575\u001b[0m       0.6375        \u001b[31m0.7800\u001b[0m  0.0251\n",
      "     23            0.7285        \u001b[32m0.6400\u001b[0m       \u001b[35m0.6500\u001b[0m        \u001b[31m0.7698\u001b[0m  0.0246\n",
      "     24            0.7219        0.6481       \u001b[35m0.6625\u001b[0m        \u001b[31m0.7578\u001b[0m  0.0216\n",
      "     25            \u001b[36m0.7550\u001b[0m        \u001b[32m0.6182\u001b[0m       0.6625        \u001b[31m0.7455\u001b[0m  0.0221\n",
      "[CV] ........................ net__module__num_units=60, total=   0.8s\n",
      "[CV] net__module__num_units=60 .......................................\n",
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "Re-initializing optimizer.\n",
      "  epoch    accuracy_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------------  ------------  -----------  ------------  ------\n",
      "      1            \u001b[36m0.3656\u001b[0m        \u001b[32m1.1045\u001b[0m       \u001b[35m0.4321\u001b[0m        \u001b[31m1.0616\u001b[0m  0.0251\n",
      "      2            \u001b[36m0.4361\u001b[0m        \u001b[32m1.0723\u001b[0m       \u001b[35m0.4815\u001b[0m        \u001b[31m1.0303\u001b[0m  0.0226\n",
      "      3            \u001b[36m0.4912\u001b[0m        \u001b[32m1.0417\u001b[0m       \u001b[35m0.5679\u001b[0m        \u001b[31m1.0021\u001b[0m  0.0211\n",
      "      4            \u001b[36m0.5419\u001b[0m        \u001b[32m1.0161\u001b[0m       \u001b[35m0.6173\u001b[0m        \u001b[31m0.9751\u001b[0m  0.0226\n",
      "      5            \u001b[36m0.5573\u001b[0m        \u001b[32m0.9942\u001b[0m       0.6049        \u001b[31m0.9494\u001b[0m  0.0221\n",
      "      6            \u001b[36m0.5661\u001b[0m        \u001b[32m0.9723\u001b[0m       \u001b[35m0.6296\u001b[0m        \u001b[31m0.9237\u001b[0m  0.0226\n",
      "      7            \u001b[36m0.5969\u001b[0m        \u001b[32m0.9460\u001b[0m       0.6296        \u001b[31m0.8993\u001b[0m  0.0201\n",
      "      8            \u001b[36m0.6145\u001b[0m        \u001b[32m0.9291\u001b[0m       \u001b[35m0.6543\u001b[0m        \u001b[31m0.8771\u001b[0m  0.0216\n",
      "      9            \u001b[36m0.6344\u001b[0m        \u001b[32m0.8945\u001b[0m       \u001b[35m0.6667\u001b[0m        \u001b[31m0.8556\u001b[0m  0.0261\n",
      "     10            \u001b[36m0.6454\u001b[0m        \u001b[32m0.8786\u001b[0m       0.6667        \u001b[31m0.8348\u001b[0m  0.0216\n",
      "     11            \u001b[36m0.6564\u001b[0m        \u001b[32m0.8478\u001b[0m       0.6543        \u001b[31m0.8153\u001b[0m  0.0216\n",
      "     12            \u001b[36m0.6828\u001b[0m        \u001b[32m0.8249\u001b[0m       0.6543        \u001b[31m0.7971\u001b[0m  0.0231\n",
      "     13            0.6454        \u001b[32m0.8071\u001b[0m       0.6543        \u001b[31m0.7807\u001b[0m  0.0246\n",
      "     14            0.6696        \u001b[32m0.7903\u001b[0m       0.6667        \u001b[31m0.7652\u001b[0m  0.0281\n",
      "     15            \u001b[36m0.7181\u001b[0m        \u001b[32m0.7704\u001b[0m       0.6667        \u001b[31m0.7501\u001b[0m  0.0226\n",
      "     16            0.7004        \u001b[32m0.7510\u001b[0m       \u001b[35m0.6790\u001b[0m        \u001b[31m0.7367\u001b[0m  0.0216\n",
      "     17            \u001b[36m0.7203\u001b[0m        \u001b[32m0.7212\u001b[0m       \u001b[35m0.7037\u001b[0m        \u001b[31m0.7232\u001b[0m  0.0226\n",
      "     18            0.7026        \u001b[32m0.7175\u001b[0m       \u001b[35m0.7160\u001b[0m        \u001b[31m0.7106\u001b[0m  0.0256\n",
      "     19            0.7093        \u001b[32m0.7123\u001b[0m       0.7160        \u001b[31m0.6986\u001b[0m  0.0231\n",
      "     20            \u001b[36m0.7401\u001b[0m        \u001b[32m0.6891\u001b[0m       0.7160        \u001b[31m0.6867\u001b[0m  0.0236\n",
      "     21            0.7159        \u001b[32m0.6747\u001b[0m       0.7160        \u001b[31m0.6755\u001b[0m  0.0216\n",
      "     22            0.7048        \u001b[32m0.6648\u001b[0m       0.7160        \u001b[31m0.6650\u001b[0m  0.0231\n",
      "     23            \u001b[36m0.7445\u001b[0m        \u001b[32m0.6373\u001b[0m       0.7160        \u001b[31m0.6551\u001b[0m  0.0211\n",
      "     24            0.7401        0.6412       \u001b[35m0.7284\u001b[0m        \u001b[31m0.6465\u001b[0m  0.0226\n",
      "     25            0.7379        \u001b[32m0.6128\u001b[0m       0.7284        \u001b[31m0.6382\u001b[0m  0.0231\n",
      "[CV] ........................ net__module__num_units=60, total=   0.8s\n",
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: num_units.\n",
      "Re-initializing optimizer.\n",
      "  epoch    accuracy_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ----------------  ------------  -----------  ------------  ------\n",
      "      1            \u001b[36m0.3368\u001b[0m        \u001b[32m1.1029\u001b[0m       \u001b[35m0.3917\u001b[0m        \u001b[31m1.0908\u001b[0m  0.0321\n",
      "      2            \u001b[36m0.4368\u001b[0m        \u001b[32m1.0629\u001b[0m       \u001b[35m0.4500\u001b[0m        \u001b[31m1.0673\u001b[0m  0.0351\n",
      "      3            \u001b[36m0.5132\u001b[0m        \u001b[32m1.0298\u001b[0m       \u001b[35m0.4667\u001b[0m        \u001b[31m1.0446\u001b[0m  0.0346\n",
      "      4            \u001b[36m0.5206\u001b[0m        \u001b[32m1.0041\u001b[0m       \u001b[35m0.5167\u001b[0m        \u001b[31m1.0223\u001b[0m  0.0366"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    4.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      5            \u001b[36m0.5324\u001b[0m        \u001b[32m0.9688\u001b[0m       \u001b[35m0.5417\u001b[0m        \u001b[31m1.0006\u001b[0m  0.0321\n",
      "      6            \u001b[36m0.5765\u001b[0m        \u001b[32m0.9388\u001b[0m       0.5417        \u001b[31m0.9783\u001b[0m  0.0371\n",
      "      7            \u001b[36m0.5809\u001b[0m        \u001b[32m0.9148\u001b[0m       \u001b[35m0.5500\u001b[0m        \u001b[31m0.9555\u001b[0m  0.0321\n",
      "      8            \u001b[36m0.5971\u001b[0m        \u001b[32m0.8950\u001b[0m       \u001b[35m0.5750\u001b[0m        \u001b[31m0.9303\u001b[0m  0.0346\n",
      "      9            \u001b[36m0.6147\u001b[0m        \u001b[32m0.8672\u001b[0m       \u001b[35m0.5917\u001b[0m        \u001b[31m0.9027\u001b[0m  0.0321\n",
      "     10            0.6088        \u001b[32m0.8532\u001b[0m       0.5750        \u001b[31m0.8759\u001b[0m  0.0316\n",
      "     11            \u001b[36m0.6471\u001b[0m        \u001b[32m0.8238\u001b[0m       0.5917        \u001b[31m0.8511\u001b[0m  0.0321\n",
      "     12            0.6456        \u001b[32m0.8002\u001b[0m       \u001b[35m0.6167\u001b[0m        \u001b[31m0.8284\u001b[0m  0.0366\n",
      "     13            \u001b[36m0.6529\u001b[0m        \u001b[32m0.7944\u001b[0m       \u001b[35m0.6500\u001b[0m        \u001b[31m0.8067\u001b[0m  0.0321\n",
      "     14            \u001b[36m0.6794\u001b[0m        \u001b[32m0.7652\u001b[0m       \u001b[35m0.6750\u001b[0m        \u001b[31m0.7864\u001b[0m  0.0316\n",
      "     15            0.6647        \u001b[32m0.7513\u001b[0m       \u001b[35m0.6833\u001b[0m        \u001b[31m0.7672\u001b[0m  0.0316\n",
      "     16            \u001b[36m0.6956\u001b[0m        \u001b[32m0.7384\u001b[0m       0.6833        \u001b[31m0.7510\u001b[0m  0.0331\n",
      "     17            0.6735        \u001b[32m0.7171\u001b[0m       0.6833        \u001b[31m0.7376\u001b[0m  0.0311\n",
      "     18            0.6926        \u001b[32m0.7083\u001b[0m       \u001b[35m0.7083\u001b[0m        \u001b[31m0.7270\u001b[0m  0.0316\n",
      "     19            \u001b[36m0.7118\u001b[0m        \u001b[32m0.7082\u001b[0m       0.6917        \u001b[31m0.7158\u001b[0m  0.0301\n",
      "     20            0.7059        \u001b[32m0.6868\u001b[0m       0.6917        \u001b[31m0.7053\u001b[0m  0.0301\n",
      "     21            \u001b[36m0.7191\u001b[0m        \u001b[32m0.6594\u001b[0m       0.6833        \u001b[31m0.6969\u001b[0m  0.0326\n",
      "     22            \u001b[36m0.7250\u001b[0m        \u001b[32m0.6430\u001b[0m       0.6917        \u001b[31m0.6878\u001b[0m  0.0341\n",
      "     23            \u001b[36m0.7500\u001b[0m        \u001b[32m0.6343\u001b[0m       0.6917        \u001b[31m0.6797\u001b[0m  0.0336\n",
      "     24            0.7206        0.6390       0.7000        \u001b[31m0.6701\u001b[0m  0.0366\n",
      "     25            0.7309        \u001b[32m0.6218\u001b[0m       0.7000        \u001b[31m0.6607\u001b[0m  0.0316\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('net', net)\n",
    "])\n",
    "\n",
    "grid = {\n",
    "    'net__module__num_units': [50, 60]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    estimator=pipe, \n",
    "    param_grid=grid,\n",
    "    scoring='accuracy',\n",
    "    cv=3,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "predictions = gs.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[47,  6, 18],\n",
       "       [ 6, 51,  6],\n",
       "       [14,  9, 43]], dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\se.vi.dmitriev\\python-virtual-environments\\pytorch\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type NetClassifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "c:\\users\\se.vi.dmitriev\\python-virtual-environments\\pytorch\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "c:\\users\\se.vi.dmitriev\\python-virtual-environments\\pytorch\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "c:\\users\\se.vi.dmitriev\\python-virtual-environments\\pytorch\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type NLLLoss. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# Save model gs\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(gs, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
